{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>Welcome to the documentation for OpenCEHardware\u2019s ScaleNPU hardware module. This resource provides a comprehensive guide to understanding and working with the ScaleNPU block, detailing its current capabilities, configurations, and design specifications.</p>"},{"location":"#navigation","title":"Navigation","text":"<p>To help you get the most out of this documentation, we've organized it into the following sections:</p> <ul> <li> Revisions: Documentation on previous versions and changes made.</li> <li> Document Conventions: Definitions and abbreviations used in the document.</li> <li> Introduction: General description of the ScaleNPU and its features.</li> <li> Block Diagram: Visual representation of the ScaleNPU microarchitecture.</li> <li> Configuration: Information about parameters, typedefs, and RTL interfaces.</li> <li> Protocols: Details of communication and operation protocols.</li> <li> Memory Map: Distribution of memory and resource allocation.</li> <li> Registers: Description of the registers used in the system.</li> <li> Clock Domains: Information about clocks and their management in the system.</li> <li> Reset Domains: Information about reset mechanisms and their domains.</li> <li> Interrupts: Management and handling of interrupts in the system.</li> <li> Arbitration: Arbitration mechanisms for access to shared resources.</li> <li> Debugging: Techniques and tools for system debugging.</li> <li> Synthesis: Summary and results of the design synthesis.</li> <li> Verification: Test environments, verification and testbenches applied to the system.</li> <li>Microarquitecture Preamble: Overview of the teorical principles, data flow, and design rationale behind the ScaleNPU\u2019s microarchitecture.</li> <li>Microarchitecture:<ul> <li> MAC: Multiply-accumulate unit for core computational operations.</li> <li> FIFO: First-In-First-Out buffers for data handling and synchronization.</li> <li> Gatekeeper: Access control and resource management.</li> <li> Accumulator: Accumulation of computation results.</li> <li> Activation: Activation function application for inference.</li> <li> Systolic Array: Systolic data flow for matrix operations.</li> <li> Inference: Management of inference processes.</li> <li> Memory Ordering: Ordering and management of memory requests.</li> <li> Memory Interface: Interface for accessing external memory resources.</li> <li> Executive: Control and orchestration of the ScaleNPU\u2019s operations.</li> </ul> </li> </ul>"},{"location":"#acknowledgements","title":"Acknowledgements","text":"<p>Please check the References section for more information.</p>"},{"location":"about/","title":"Authors","text":"<p>This documentation has been developed as part of a graduation project in Computer Engineering. Below are the authors responsible for the creation and development of this document:</p> <ul> <li>Alejandro Chavarr\u00eda</li> <li>Alejandro Soto</li> </ul> <p>For more information about the project, please refer to the associated GitHub organization OpenCEHardware.</p>"},{"location":"block/arbitration/","title":"Arbitration, Fairness, QoS, and Forward Progress Guarantees","text":"<p>The ScaleNPU operates as a single slave module within a system, meaning it doesn\u2019t manage multiple traffic classes or arbitration directly. Instead, it relies on the AXI protocol for memory access, where arbitration and resource sharing are handled by the AXI interconnect. This interconnect manages how memory requests from the ScaleNPU are prioritized and ensures fair access among all system modules.</p>"},{"location":"block/arbitration/#arbitration-and-fairness","title":"Arbitration and Fairness","text":"<p>The ScaleNPU delegates arbitration to the AXI interconnect, which could use round-robin or priority-based policies based on system configuration. This setup ensures that the ScaleNPU's memory requests are fairly managed alongside other AXI-connected masters, with no need for the ScaleNPU itself to enforce fairness.</p> <ul> <li>Arbitration and Fairness: Managed by the AXI interconnect, not the ScaleNPU.  </li> <li>Configurability: AXI settings determine arbitration behavior.</li> </ul>"},{"location":"block/arbitration/#quality-of-service-qos","title":"Quality-of-Service (QoS)","text":"<p>Any QoS or priority configurations are also managed by the AXI interconnect. This allows the system to prioritize the ScaleNPU\u2019s memory transactions if needed but is configured at the system level rather than within the ScaleNPU.</p> <ul> <li>QoS Control: Assigned via AXI, influencing transaction prioritization among connected modules.</li> </ul>"},{"location":"block/arbitration/#forward-progress","title":"Forward Progress","text":"<p>The AXI protocol ensures forward progress by preventing deadlock and livelock, guaranteeing that all requests are eventually serviced as long as the interconnect adheres to AXI standards.</p> <ul> <li>Guarantees: Deadlock prevention and transaction progress are enforced by AXI protocol compliance, not by the ScaleNPU.</li> </ul>"},{"location":"block/clocks/","title":"Clock Domains","text":"<p>The ScaleNPU operates on a single clock domain shared by all modules. It was tested with a 50MHz clock on the DE1-SoC and DE10-Nano plataforms. No dynamic range support was tested for any module. </p>"},{"location":"block/configuration/","title":"Configuration","text":"<p>The ScaleNPU was designed with a focus on flexibility, allowing for extensive configurability and parameterization. While the current implementation includes several configurable parameters, many have only been tested with their default values.</p>"},{"location":"block/configuration/#parameters","title":"Parameters","text":"Parameter Name Type Description Default Value Range/Possible Values <code>SIZE</code> <code>int</code> Number of rows and columns in the systolic array. <code>8</code> Positive integer (limited by FPGA DSP blocks) <code>INPUT_DATA_WIDTH</code> <code>int</code> Bit width for input data values in the systolic array. <code>16</code> <code>8</code>, <code>16</code>, <code>32</code>, <code>64</code> <code>WEIGHT_DATA_WIDTH</code> <code>int</code> Bit width for weight values in the systolic array. <code>16</code> <code>8</code>, <code>16</code>, <code>32</code>, <code>64</code> <code>OUTPUT_DATA_WIDTH</code> <code>int</code> Bit width for output data from MAC operations.  It also defines bias and sum data width. <code>32</code> <code>8</code>, <code>16</code>, <code>32</code>, <code>64</code> <code>ACTIVATION_OUTPUT_WIDTH</code> <code>int</code> Bit width for output after the activation (and quantization) function. <code>16</code> Should match <code>INPUT_DATA_WIDTH</code> <code>BUFFER_SIZE</code> <code>int</code> Maximum number of inferences stored in SDRAM. <code>16</code> Based on SDRAM capacity and application <code>INPUT_FIFO_DEPTH</code> <code>int</code> Depth of the input FIFO buffer. <code>16</code> Should match <code>BUFFER_SIZE</code> <code>OUTPUT_FIFO_DEPTH</code> <code>int</code> Depth of the output FIFO buffer. <code>16</code> Should match <code>BUFFER_SIZE</code> <code>WEIGHT_FIFO_DEPTH</code> <code>int</code> Depth of the weight FIFO buffer. <code>8</code> Typically smaller than input/output buffers. Minimum is <code>SIZE</code> <code>BURST_SIZE</code> <code>int</code> Burst size for AXI RAM transfers (2^N bytes). <code>2</code> Positive integer; should align with input and weight sizes <code>BURST_LEN</code> <code>int</code> Length of the burst in 32-bit word transfers. <code>1</code> Positive integer <p>Remarks:</p> <ul> <li><code>BURST_SIZE</code> and <code>BURST_LEN</code> follow AXI protocol limitations, directly influencing memory ordering behavior.</li> <li>FIFO depths depend on SDRAM limits in the FPGA, so testing beyond default values could reveal memory constraints. Default values are close to minimum requirements.</li> </ul>"},{"location":"block/configuration/#typedefs","title":"Typedefs","text":"Typedef Name Type Description <code>word</code> <code>logic signed [31:0]</code> A signed 32-bit data type used in operations like MAC. <code>short</code> <code>logic signed [15:0]</code> A signed 16-bit data type for inputs and weights. <code>uword</code> <code>logic [31:0]</code> An unsigned 32-bit data type used in memory or control ops. <p>These typedefs ensure consistent data sizing across the architecture.</p>"},{"location":"block/configuration/#supported-parameter-variations","title":"Supported Parameter Variations","text":"<p>Due to time constraints, the ScaleNPU's parameterization has been primarily tested with default values. Most limitations arise in the memory management unit, given its rigid handling of <code>BURST_SIZE</code> and <code>BURST_LEN</code> in relation to the systolic array size, input/weight/output bit widths, and buffer capacities. Extending functionality to support all potential parameter combinations would require significantly more logic, especially in the memory ordering and interface units.</p> <p>Warning</p> <p>Current configurations outside of the default values may not guarantee proper operation of the ScaleNPU.</p> <p>The following table outlines some potential issues and solutions related to specific parameters:</p> Parameter Name Likelihood of Failure Reason for Failure Possible Solution <code>SIZE</code> Medium, if DSP constraints are respected. Memory ordering might not fill the array if <code>SIZE</code> is not divisible by <code>BURST_LEN</code>. With <code>SIZE=8</code>, four 2-beat requests fill the array's 8 rows/columns. Add logic to handle unaligned bursts <code>INPUT_DATA_WIDTH</code>, <code>WEIGHT_DATA_WIDTH</code>, <code>OUTPUT_DATA_WIDTH</code> Low, but may require adjusting burst parameters. Current 16-bit default guards against overflow; larger values may increase DSP needs and require burst adjustments. Adjust burst sizes/lengths to handle larger data widths, prevent overflow <code>ACTIVATION_OUTPUT_WIDTH</code> Low, but may also require burst adjustments. As above, larger widths may increase DSP needs and affect burst sizes/lengths. Same as above <code>BUFFER_SIZE</code> Very low. NPU may exit with code <code>11</code> if buffer size is too small for CPU inputs. Increase buffer size or perform inference on fewer inputs at a time. <code>BURST_SIZE</code> Medium. Misalignment with input, weight, and bias widths Ensure proper alignment, or refactor memory ordering/interface state machines <code>BURST_LEN</code> High. Hardcoded logic in memory ordering unit expects default values Refactor memory ordering/interface state machines to support flexibility <p>Note</p> <p>For DE1-SoC and DE1-Nano boards, altering these parameters is generally unnecessary, as the default implementation is sufficient for most academic projects. An appropriate driver could abstract many of these implementation details.</p>"},{"location":"block/conventions/","title":"Document Conventions","text":"<p>This section lists the conventions in terms of definitions and abbreviations that will be used throughout the document.</p>"},{"location":"block/conventions/#glossary","title":"Glossary","text":"<ul> <li>Word: Meaning</li> </ul>"},{"location":"block/conventions/#abbreviations","title":"Abbreviations","text":"<ul> <li>NPU: Neural Processign Unit</li> <li>TPU: Tensor Processign Unit</li> <li>IRQ: Interrupt Request</li> <li>CSR: Control-Status Register</li> </ul>"},{"location":"block/debugging/","title":"Debugging","text":"<p>The ScaleNPU currently has minimal debugging mechanisms, as its design focused on operation without extensive diagnostic features. There are no dedicated debugging registers or interfaces in this version, and the debugging capabilities are limited to the standard Control and Status Registers (CSRs) that provide basic monitoring of operation status.</p> <p>Future iterations of the ScaleNPU could incorporate additional CSRs specifically for debugging purposes, allowing for better diagnostics and greater visibility into internal states and operations to aid in troubleshooting and performance tuning.</p>"},{"location":"block/diagram/","title":"Top-Level Block Diagram","text":"<p>This diagram provides a simplified view (in terms of signals) of the top-level <code>.sv</code> file of the system. </p> XPU-Top lvl <p>Note</p> <p>All blocks share common clock and reset signals, which are omitted in the diagram to improve visual clarity.</p>"},{"location":"block/diagram/#1-control-status-registers-csr","title":"1. Control-Status Registers (CSR)","text":"<ul> <li>Function: Interfaces with the CPU to configure and control the NPU's operations. The CPU uses these registers to send control signals, such as initializing tasks, specifying memory addresses, and setting matrix dimensions. The CSR block also triggers interrupts (IRQ) back to the CPU to signal task completion.</li> <li>Interface: Communicates with the CPU via AXI4 Lite (control signals) and sends IRQ signals to notify task completions.</li> </ul>"},{"location":"block/diagram/#2-executive","title":"2. Executive","text":"<ul> <li>Function: Acts as the central controller for the NPU, interpreting commands received from the Control-Status Registers and coordinating tasks across the NPU blocks. It issues control signals to manage data movement and computation.</li> <li>Communication: Receives hardware control signals from the Control-Status Registers and sends control signals to the Memory Ordering block.</li> </ul>"},{"location":"block/diagram/#3-memory-ordering","title":"3. Memory Ordering","text":"<ul> <li>Function: Manages memory requests and organizes the sequence of operations, ensuring correct order in memory access. It coordinates the loading of input data and weights and the storing of output data, managing communication between the Memory Interface and the Inference block. And the exection timings of the inference block.</li> <li>Communication: Exchanges control signals with the Executive, manages data flow from the Memory Interface, and directs output data to the Inference block.</li> </ul>"},{"location":"block/diagram/#4-memory-interface","title":"4. Memory Interface","text":"<ul> <li>Function: Transfers data between external memory (RAM) and the NPU, using the AXI4 Burst protocol to retrieve inputs (such as matrices and weights) and store output data.</li> <li>Communication: Connects to RAM using the AXI4 Burst protocol for high-speed data access and exchanges control and data signals with the Memory Ordering block.</li> </ul>"},{"location":"block/diagram/#5-inference-block","title":"5. Inference Block","text":"<ul> <li>Function: The computational core of the NPU, performing matrix operations like multiplication and accumulation. It processes data loaded from memory (inputs, weights, bias, etc.) to produce the final inference results.</li> <li>Communication: Receives data and control signals from the Memory Ordering block and outputs results after completing computations.</li> </ul>"},{"location":"block/diagram/#6-ram","title":"6. RAM","text":"<ul> <li>Function: External memory that stores data such as matrices, weights, and (if required) intermediate results. The Memory Interface retrieves and writes data to RAM during NPU operations.</li> </ul>"},{"location":"block/diagram/#7-cpu","title":"7. CPU","text":"<ul> <li>Function: The host processor that configures and controls the NPU. It sets up tasks through the Control-Status Registers and responds to IRQ signals from the NPU to manage overall system operation.</li> </ul>"},{"location":"block/diagram/#microarchitecture-diagram","title":"Microarchitecture Diagram","text":"<p>This diagram offers a closer, yet more abstract, view of the NPU. While it doesn\u2019t map 1:1 to specific <code>.sv</code> files or individual hardware blocks, it represents a high-level simplification of the NPU architecture, highlighting key components and their interactions.</p> XPU-Uarch"},{"location":"block/interrupts/","title":"Interrupts","text":"<p>The ScaleNPU implements a single interrupt to signal the CPU upon completion of a processing task.  This interrupt mechanism informs the CPU only when the NPU has finished a previous query. The interrupt must be handled and cleared by the CPU before initiating any new query, ensuring proper synchronization between the CPU and the NPU.</p>"},{"location":"block/introduction/","title":"Introduction","text":"<p>The ScaleNPU is an AI accelerator designed to efficiently handle simple matrix multiplication operations for neural network inference. It is architected for integration in heterogeneous CPU+accelerator systems, providing a dedicated block for accelerating machine learning tasks. The design is modular, scalable, and configurable, focusing on optimizing system resources and performance.</p>"},{"location":"block/introduction/#blackbox-top-level-diagram","title":"Blackbox Top-level Diagram","text":""},{"location":"block/introduction/#goals-and-non-goals","title":"Goals and Non-Goals","text":""},{"location":"block/introduction/#goals","title":"Goals","text":"<ul> <li>Efficiently accelerate matrix operations, primarily for neural network inference.</li> <li>Seamlessly integrate with CPU-based systems on FPGA platforms.</li> <li>Optimize resource usage in FPGA environments, minimizing memory consumption while maximizing throughput.</li> </ul>"},{"location":"block/introduction/#non-goals","title":"Non-Goals","text":"<ul> <li>ScaleNPU is not designed for floating-point operations or general-purpose computing.</li> <li>It is not intended to replace the CPU, but rather to complement it in specific AI-related tasks.</li> </ul>"},{"location":"block/introduction/#features","title":"Features","text":"<p>The main function of the ScaleNPU block is to efficiently perform neural network (NN) inference. Key capabilities include:</p> <ul> <li>Matrix multiplication: Support for matrix multiplication of any size.</li> <li>Bias accumulation: Support for adding bias vectors at the layer level.</li> <li>Non-linear activation function: Support for ReLU (Rectified Linear Unit) activation.</li> <li>Re-quantization during inference: Support for symmetric power-of-two quantization of results.</li> </ul>"},{"location":"block/introduction/#debugging-features","title":"Debugging Features","text":"<p>The ScaleNPU includes several features to aid in debugging:</p> <ul> <li>Status registers: Provide visibility into the internal state of the NPU for monitoring.</li> <li>Testbench support: A verification environment using cocotb and other simulation tools to ensure functional correctness.</li> </ul>"},{"location":"block/introduction/#integration-and-system-context","title":"Integration and System Context","text":"<p>ScaleNPU is designed to be integrated into larger heterogeneous computing systems, particularly within the H-SCALE framework, which combines a RISC-V CPU with AI accelerators for educational purposes. It communicates with the CPU and memory systems using standard protocols like AXI, and uses DMA for efficient data transfers during matrix operations. The unit is controlled via configuration registers (CSRs), allowing the CPU to manage operations and initiate tasks.</p>"},{"location":"block/introduction/#standard-protocols","title":"Standard Protocols","text":"<p>The ScaleNPU uses the following standard communication protocols: - AXI Protocol: AXI4 Burst for high-speed memory access and AXI4-Lite for control signal exchanges between the accelerator and the system. - CSR (Control and Status Registers): Provides configuration and control mechanisms for interfacing with the host CPU. - IRQ Line: Provides an interrupt request output line for CPU or peripheral IRQs.</p> <p>Note</p> <p>Performance is highly dependent on the actual parameters of the implementation and the characteristics of the FPGA. Memory speed, register availability, and clock speeds will impact the overall performance of the block.</p>"},{"location":"block/memory/","title":"Memory Map","text":"<p>The ScaleNPU operates as a slave unit, meaning its memory map is defined by the host system\u2019s interconnect configuration. Details specific to Control and Status Register (CSR) mapping are provided in the next section of this documentation.</p>"},{"location":"block/protocols/","title":"Protocols","text":"<p>This section outlines the protocols used by the ScaleNPU for inter-module communication and interaction with external components. Both standard protocols are described to ensure clarity in data transfer and control sequences across the NPU. Standard protocols are linked to their specifications.</p>"},{"location":"block/protocols/#standard-protocols","title":"Standard Protocols","text":""},{"location":"block/protocols/#axi4-burst-protocol","title":"AXI4 Burst Protocol","text":"<ul> <li>Description: The AXI4 (Advanced eXtensible Interface 4) Burst protocol is used for  memory access, allowing data to be transferred in bursts to optimize bandwidth. In the ScaleNPU, AXI4 Burst is used by the Memory Interface to interact with RAM for loading input data and storing output results.</li> <li>Specification: AXI4 Burst Protocol Specification</li> </ul>"},{"location":"block/protocols/#axi4-lite-protocol","title":"AXI4-Lite Protocol","text":"<ul> <li>Description: AXI4-Lite is a lightweight version of the AXI4 protocol, intended for simpler control and configuration transactions with low bandwidth requirements. The ScaleNPU uses AXI4-Lite for communication between the Control-Status Registers (CSR) and the CPU, allowing the CPU to configure the NPU\u2019s operation and retrieve status information.</li> <li>Specification: AXI4-Lite Protocol Specification</li> </ul>"},{"location":"block/protocols/#ready-valid-protocol","title":"Ready-Valid Protocol","text":"<ul> <li>Description: Internally, ScaleNPU loosely follows a Ready-Valid protocol for handshaking between modules. This protocol is widely used across the NPU\u2019s modules to coordinate the exchange of data and control signals. Most modules have a <code>ready</code> and <code>valid</code> signals, though they are not always used. This is due manly because of the predictable behavoir of the unit, allowing for logic simplifications and cycle efficiency. </li> </ul> <p>Note</p> <p>Here are some great videos to undertand this protocols: AXI tutorial</p>"},{"location":"block/references/","title":"References","text":"<p>Link to other related documents\u2009\u2014\u2009test plans, design information, source code location, protocol documents, chip-level specifications, etc. [1] Also link to any external papers, hardware, protocols or ideas used in the document.</p> <p>In this case the example links to the actual refernces used to elaborate this guide.</p> <p> [1] Gottscho, M. (2024, February 20). A Template for Writing a Microarchitecture Specification. Retrieved from https://markgottscho.com/posts/2024/02/20/uarch-spec-template/</p> <p> [2] Herveille, R. (2003, July 3). I\u00b2C-Master Core Specification (Rev. 0.9). OpenCores. Retrieved from https://github.com/freecores/i2c/blob/master/doc/i2c_specs.pdf</p>"},{"location":"block/registers/","title":"Registers","text":"<p>This section lists all registers in the ScaleNPU block, which include only the Control and Status Registers (CSRs).</p>"},{"location":"block/registers/#csrs-configurationstatus-registers","title":"CSRs (Configuration/Status Registers)","text":"<p>The Control and Status Registers (CSRs) in the ScaleNPU provide a direct interface for the CPU to configure, monitor, and control NPU operations. Through these registers, the CPU can set up tasks by specifying parameters such as matrix dimensions, memory addresses, and operational modes, and initiate processing tasks for a single layer calculation. The CSRs also allow the CPU to monitor the NPU's status, check task completion, detect errors, and manage task-related interrupts.</p> <p>The following CSR sections were auto-generated by PeakRDL using the .rdl file as the source.</p>"},{"location":"block/registers/#hs_npu_ctrlstatus_regs-address-map","title":"hs_npu_ctrlstatus_regs address map","text":"<ul> <li>Absolute Address: 0x0</li> <li>Base Offset: 0x0</li> <li>Size: 0x48</li> </ul> <p>Control and status registers for configuring the Scale NPU.</p> Offset Identifier Name 0x00 NPUINFO Accelerator Information 0x08 DIMS Matrix Dimensions 0x18 CTRL Layer Control Flags 0x34 MEMADDRS Memory Addresses 0x3C MAINCTRL Main control registers"},{"location":"block/registers/#npuinfo-register-file","title":"NPUINFO register file","text":"<ul> <li>Absolute Address: 0x0</li> <li>Base Offset: 0x0</li> <li>Size: 0x8</li> </ul> <p>Contains registers that provide architecture and implementation details of the accelerator.</p> Offset Identifier Name 0x0 ARCHID Architecture ID 0x4 IMPID Implementation ID"},{"location":"block/registers/#archid-register","title":"ARCHID register","text":"<ul> <li>Absolute Address: 0x0</li> <li>Base Offset: 0x0</li> <li>Size: 0x4</li> </ul> <p>Encodes the base microarchitecture of the accelerator.</p> Bits Identifier Access Reset Name 31:0 ID r 0xB00B \u2014"},{"location":"block/registers/#impid-register","title":"IMPID register","text":"<ul> <li>Absolute Address: 0x4</li> <li>Base Offset: 0x4</li> <li>Size: 0x4</li> </ul> <p>Provides a unique encoding of the version of the accelerator implementation.</p> Bits Identifier Access Reset Name 31:0 ID r 0x100 \u2014"},{"location":"block/registers/#dims-register-file","title":"DIMS register file","text":"<ul> <li>Absolute Address: 0x8</li> <li>Base Offset: 0x8</li> <li>Size: 0x10</li> </ul> <p>Registers for specifying the dimensions of input and weight matrices.</p> Offset Identifier Name 0x0 INROWS Input Matrix Rows 0x4 INCOLS Input Matrix Columns 0x8 WGHTROWS Weight Matrix Rows 0xC WGHTCOLS Weight Matrix Columns"},{"location":"block/registers/#inrows-register","title":"INROWS register","text":"<ul> <li>Absolute Address: 0x8</li> <li>Base Offset: 0x0</li> <li>Size: 0x4</li> </ul> <p>Number of rows in the input matrix.</p> Bits Identifier Access Reset Name 7:0 ROWS rw \u2014 \u2014"},{"location":"block/registers/#incols-register","title":"INCOLS register","text":"<ul> <li>Absolute Address: 0xC</li> <li>Base Offset: 0x4</li> <li>Size: 0x4</li> </ul> <p>Number of columns in the input matrix.</p> Bits Identifier Access Reset Name 7:0 COLS rw \u2014 \u2014"},{"location":"block/registers/#wghtrows-register","title":"WGHTROWS register","text":"<ul> <li>Absolute Address: 0x10</li> <li>Base Offset: 0x8</li> <li>Size: 0x4</li> </ul> <p>Number of rows in the weight matrix.</p> Bits Identifier Access Reset Name 7:0 ROWS rw \u2014 \u2014"},{"location":"block/registers/#wghtcols-register","title":"WGHTCOLS register","text":"<ul> <li>Absolute Address: 0x14</li> <li>Base Offset: 0xC</li> <li>Size: 0x4</li> </ul> <p>Number of columns in the weight matrix.</p> Bits Identifier Access Reset Name 7:0 COLS rw \u2014 \u2014"},{"location":"block/registers/#ctrl-register-file","title":"CTRL register file","text":"<ul> <li>Absolute Address: 0x18</li> <li>Base Offset: 0x18</li> <li>Size: 0x1C</li> </ul> <p>Registers for configuring control signals of a particular layer calculation.</p> Offset Identifier Name 0x00 REINPUTS Results as Input 0x04 REWEIGHTS Reuse Weights 0x08 SAVEOUT Save Output 0x0C USEBIAS Use Bias 0x10 USESUMM Use Summatory 0x14 SHIFTAMT Shift Amount 0x18 ACTFN Activation Function Selection"},{"location":"block/registers/#reinputs-register","title":"REINPUTS register","text":"<ul> <li>Absolute Address: 0x18</li> <li>Base Offset: 0x0</li> <li>Size: 0x4</li> </ul> <p>Flag to use the results of the previous layer calculation as the input matrix.</p> Bits Identifier Access Reset Name 0 REUSE rw \u2014 \u2014"},{"location":"block/registers/#reweights-register","title":"REWEIGHTS register","text":"<ul> <li>Absolute Address: 0x1C</li> <li>Base Offset: 0x4</li> <li>Size: 0x4</li> </ul> <p>Flag to reuse the weights of the previous layer computation.</p> Bits Identifier Access Reset Name 0 REUSE rw \u2014 \u2014"},{"location":"block/registers/#saveout-register","title":"SAVEOUT register","text":"<ul> <li>Absolute Address: 0x20</li> <li>Base Offset: 0x8</li> <li>Size: 0x4</li> </ul> <p>Flag to save the output after layer computation.</p> Bits Identifier Access Reset Name 0 SAVE rw \u2014 \u2014"},{"location":"block/registers/#usebias-register","title":"USEBIAS register","text":"<ul> <li>Absolute Address: 0x24</li> <li>Base Offset: 0xC</li> <li>Size: 0x4</li> </ul> <p>Flag to enable bias addition during computation.</p> Bits Identifier Access Reset Name 0 USE rw \u2014 \u2014"},{"location":"block/registers/#usesumm-register","title":"USESUMM register","text":"<ul> <li>Absolute Address: 0x28</li> <li>Base Offset: 0x10</li> <li>Size: 0x4</li> </ul> <p>Flag to use summatory values for the results.</p> Bits Identifier Access Reset Name 0 USE rw \u2014 \u2014"},{"location":"block/registers/#shiftamt-register","title":"SHIFTAMT register","text":"<ul> <li>Absolute Address: 0x2C</li> <li>Base Offset: 0x14</li> <li>Size: 0x4</li> </ul> <p>Amount of shift for quantization.</p> Bits Identifier Access Reset Name 7:0 AMOUNT rw \u2014 \u2014"},{"location":"block/registers/#actfn-register","title":"ACTFN register","text":"<ul> <li>Absolute Address: 0x30</li> <li>Base Offset: 0x18</li> <li>Size: 0x4</li> </ul> <p>Selects the activation function to apply (0: None, 1: ReLU).</p> Bits Identifier Access Reset Name 0 SELECT rw \u2014 \u2014"},{"location":"block/registers/#memaddrs-register-file","title":"MEMADDRS register file","text":"<ul> <li>Absolute Address: 0x34</li> <li>Base Offset: 0x34</li> <li>Size: 0x8</li> </ul> <p>Registers for setting the base memory address for matrix data and the result address.</p> Offset Identifier Name 0x0 BASE Base Memory Address 0x4 RESULT Result Memory Address"},{"location":"block/registers/#base-register","title":"BASE register","text":"<ul> <li>Absolute Address: 0x34</li> <li>Base Offset: 0x0</li> <li>Size: 0x4</li> </ul> <p>Base address in memory for matrix data.</p> Bits Identifier Access Reset Name 31:0 ADDR rw \u2014 \u2014"},{"location":"block/registers/#result-register","title":"RESULT register","text":"<ul> <li>Absolute Address: 0x38</li> <li>Base Offset: 0x4</li> <li>Size: 0x4</li> </ul> <p>Memory address for storing the result.</p> Bits Identifier Access Reset Name 31:0 ADDR rw \u2014 \u2014"},{"location":"block/registers/#mainctrl-register-file","title":"MAINCTRL register file","text":"<ul> <li>Absolute Address: 0x3C</li> <li>Base Offset: 0x3C</li> <li>Size: 0xC</li> </ul> <p>Control registers to signal the start and end of an operation.</p> Offset Identifier Name 0x0 INIT Initialize 0x4 IRQ Interrupt 0x8 EXITCODE Exit code"},{"location":"block/registers/#init-register","title":"INIT register","text":"<ul> <li>Absolute Address: 0x3C</li> <li>Base Offset: 0x0</li> <li>Size: 0x4</li> </ul> <p>Signals the NPU to start operation with the current register data.</p> Bits Identifier Access Reset Name 0 VALUE w1 \u2014 \u2014"},{"location":"block/registers/#irq-register","title":"IRQ register","text":"<ul> <li>Absolute Address: 0x40</li> <li>Base Offset: 0x4</li> <li>Size: 0x4</li> </ul> <p>Interrupt signals cominng from the NPU. Signals the NPU has finished</p> Bits Identifier Access Reset Name 0 FINISHED rw, woclr \u2014 \u2014"},{"location":"block/registers/#exitcode-register","title":"EXITCODE register","text":"<ul> <li>Absolute Address: 0x44</li> <li>Base Offset: 0x8</li> <li>Size: 0x4</li> </ul> <p>Exit code produced by the NPU once the operation finishes. UNUSED = 00, SUCCESS = 01, MEM_ERR = 10, CPU_ERR = 11</p> Bits Identifier Access Reset Name 1:0 CODE r \u2014 \u2014"},{"location":"block/resets/","title":"Reset Domains","text":"<p>The ScaleNPU operates on a single, shared reset signal. Upon power-up, it is essential to assert the reset signal for at least one full clock cycle to ensure proper initialization by clearing any residual values and resets the state machine of the memory ordering unit and memory interface to an idle state. </p> <p>Asserting this signal would also effectively stop any ongoing inference operations, regardless of the state. This means results can be lost or incomplete. </p>"},{"location":"block/revisions/","title":"Revisions","text":"Date (YYYY-MM-DD) Version Description of Changes Author 2024-??-?? <code>1.0.0</code> Document creation. Alejandro Chavarr\u00eda"},{"location":"block/synthesis/","title":"Synthesis","text":"<p>This section presents the synthesis results of the ScaleNPU across two FPGAs: DE1-SoC and DE10-Nano. The table below summarizes the usage of resources, including ALMs, registers, memory blocks, and DSPs, along with their respective utilization percentages.</p>"},{"location":"block/synthesis/#synthesis-results-table","title":"Synthesis Results Table","text":"FPGA ALMs (Usage / Total) Registers Memory Bits (Usage / Total) DSPs (Usage / Total) Comments DE1-SoC 3,744 / 32,070 (11.7%) 5,682 5,120 / 4,065,280 (0.1%) 40 / 87 (46%) Efficient usage within the board's capacity. DE10-Nano 3,754.8 / 41,910 (8.9%) 5,695 5,120 / 5,662,720 (0.09%) 40 / 112 (36%) Lower utilization than DE1-SoC, with more capacity."},{"location":"block/synthesis/#additional-comments","title":"Additional Comments","text":"<ul> <li> <p>Performance and Area: Both boards demonstrate efficient resource use, with relatively low utilization of memory bits (not accounting for external memory needed to store weights, inputs, biases, and sum values) and ALMs. DSP utilization is notable, especially on the DE1-SoC, where nearly half of the DSP resources are consumed, limiting the maximum size of the systolic array.</p> </li> <li> <p>Scalability: Resource usage is intentionally kept low to accommodate additional system components, including a CPU, interconnect, and memory, which are necessary for full system integration to effectively use the ScaleNPU as an accelerator.</p> </li> </ul>"},{"location":"block/verification/","title":"Verification","text":"<p>This section details the types of tests applied to the block, as well as the verification methodologies used in the development process.</p>"},{"location":"block/verification/#test-and-test-environment","title":"Test and test environment","text":"<p>The test environment employed various tools, simulators, and testbeds to verify the functionality and integration of the ScaleNPU. Initial functionality of the systolic array was prototyped in C++. Module-level testing was conducted using cocotb, and a complete system simulation (CPU + NPU + memory + JTAG) was carried out with Verilator. Final signal validation on FPGA hardware was achieved using Signal Tap and the Nios terminal over JTAG.</p>"},{"location":"block/verification/#tests-table","title":"Tests Table","text":"Tool Testing Directory/Repository C++ Prototype Initial concept verification of systolic array functionality Emulation cocotb Module-level tests for gatekeeper, systolic array, matrix multiplication, and inference Testbech Verilator Full-system simulation (CPU, NPU, memory, JTAG) Full system simulation Signal Tap Signal validation on FPGA N/A Nios Terminal Final system validation via JTAG N/A"},{"location":"block/verification/#test-results","title":"Test Results","text":"<p>Primary verification of AXI protocol compliance and module functionality was successfully achieved across simulated and hardware environments.</p>"},{"location":"block/verification/#benchmarks","title":"Benchmarks","text":"<p>Benchmarks were not run for this system.</p>"},{"location":"block/verification/#issues-and-resolutions","title":"Issues and Resolutions","text":"<p>The primary issues encountered during verification were related to AXI protocol compliance, particularly in subtle variations between simulated environments and FPGA hardware. </p> <p>Note</p> <p>While these issues were resolved, a more thorough verification of AXI protocol interactions with memory is advisable, as slight behavioral differences were noted between simulation and FPGA operation.</p>"},{"location":"block/verification/#issues-and-resolutions-table","title":"Issues and Resolutions Table","text":"Issue Description Resolution Simulation Error Results were inconsistent with expected behavior in AXI transactions. Adjusted RTL AXI timing parameters. <p>Warning</p> <p>This means that cocotb and verilator's models of AXI are unreliable. They can be used to verify basic functionality but they can't assure your module is AXI compliant.</p>"},{"location":"block/verification/#verification-summary","title":"Verification Summary","text":"<p>In summary, the ScaleNPU block successfully met functional specifications and demonstrated compatibility within the AXI protocol framework. Module functionality and integration were verified at multiple stages from C++ concept prototyping to hardware-based validation on the FPGA. Additional AXI protocol testing with memory could further reinforce the design's reliability.</p>"},{"location":"block/microarchitecture/accumulator/","title":"Accumulator Module","text":""},{"location":"block/microarchitecture/accumulator/#description","title":"Description","text":"<p>The Accumulator module (<code>hs_npu_accumulator</code>) performs an accumulation operation, adding a bias to each input data value and outputting the result. It accepts a bias value and enables accumulation based on a valid input signal. The accumulated result is output along with a signal indicating validity.</p> <p>The <code>OUTPUT_DATA_WIDTH</code> parameter defines the width of the input and output data, allowing flexibility for various data formats.</p>"},{"location":"block/microarchitecture/accumulator/#io-table","title":"I/O Table","text":""},{"location":"block/microarchitecture/accumulator/#input-table","title":"Input Table","text":"Input Name Direction Type Description <code>clk</code> Input <code>logic</code> Clock signal for synchronization. <code>rst_n</code> Input <code>logic</code> Reset signal (active low) to initialize the module. <code>input_data</code> Input <code>logic[OUTPUT_DATA_WIDTH-1:0]</code> Data to be accumulated with the bias value. <code>valid_i</code> Input <code>logic</code> Valid signal indicating <code>input_data</code> is ready. <code>bias_in</code> Input <code>logic[OUTPUT_DATA_WIDTH-1:0]</code> Bias value to add to <code>input_data</code>. <code>bias_en</code> Input <code>logic</code> Enable signal for updating the stored bias."},{"location":"block/microarchitecture/accumulator/#output-table","title":"Output Table","text":"Output Name Direction Type Description <code>result</code> Output <code>logic[OUTPUT_DATA_WIDTH-1:0]</code> Accumulated result after adding <code>input_data</code> and the stored bias. <code>valid_o</code> Output <code>logic</code> Signal indicating the result is valid."},{"location":"block/microarchitecture/accumulator/#module-behavior-and-data-flow","title":"Module Behavior and Data Flow","text":"<ul> <li> <p>Bias Handling: The accumulator holds a bias value, which can be updated whenever the <code>bias_en</code> signal is asserted. When <code>bias_en</code> is active, the bias is set to the value on <code>bias_in</code>; otherwise, it retains its previous value.</p> </li> <li> <p>Accumulation Process: When <code>valid_i</code> is asserted, the module adds the stored bias to the incoming <code>input_data</code> and outputs the result through <code>result</code>, with <code>valid_o</code> set high to indicate a valid output. If <code>valid_i</code> is deasserted, <code>result</code> outputs zero and <code>valid_o</code> is low, indicating no valid accumulation result.</p> </li> </ul>"},{"location":"block/microarchitecture/accumulator/#diagram","title":"Diagram","text":"<p>The diagram is trivial.</p> <p>The bias value is floped, only registered when <code>bias_en</code> is set.</p> <p>When <code>valid_i</code> is set: </p> <pre><code>    result  = input_data + bias;\n    valid_o = 1;\n</code></pre> <p>Else:</p> <pre><code>    result  = 0;\n    valid_o = 0;\n</code></pre>"},{"location":"block/microarchitecture/accumulator/#related-files","title":"Related Files","text":"File Name Type hs_npu_accumulator Top Module"},{"location":"block/microarchitecture/activation/","title":"Activation Module","text":""},{"location":"block/microarchitecture/activation/#description","title":"Description","text":"<p>The Activation Module (<code>hs_npu_activation</code>) processes data by applying an activation function (currently ReLU) and performs quantization through a configurable right shift operation. This module allows for flexible activation functions, with ReLU being implemented as a basic function. Quantization is achieved by truncating the shifted output data to the desired width, specified by the <code>OUTPUT_WIDTH</code> parameter. </p> <p>Note</p> <p>Future support for additional activation functions can be easily integrated using look-up tables, which allow efficient management and implementation of multiple activation methods.</p>"},{"location":"block/microarchitecture/activation/#io-table","title":"I/O Table","text":""},{"location":"block/microarchitecture/activation/#input-table","title":"Input Table","text":"Input Name Direction Type Description <code>input_data</code> Input <code>logic[DATA_WIDTH-1:0]</code> Data to be processed by the activation function. <code>valid_i</code> Input <code>logic</code> Signal indicating the input data is valid. <code>relu_en</code> Input <code>logic</code> Enable signal for applying ReLU activation; if low, data passes unmodified. <code>shift_amount</code> Input <code>logic[DATA_WIDTH-1:0]</code> Shift value to control the level of quantization in the output."},{"location":"block/microarchitecture/activation/#output-table","title":"Output Table","text":"Output Name Direction Type Description <code>result</code> Output <code>logic[OUTPUT_WIDTH-1:0]</code> Quantized output after activation and shift, truncated to <code>OUTPUT_WIDTH</code> bits. <code>valid_o</code> Output <code>logic</code> Valid signal indicating the output is ready."},{"location":"block/microarchitecture/activation/#module-behavior-and-data-flow","title":"Module Behavior and Data Flow","text":"<ol> <li> <p>ReLU Activation: When <code>relu_en</code> is high, the ReLU function is applied to <code>input_data</code>. The module outputs the maximum of <code>input_data</code> and 0, effectively setting negative values to zero. If <code>relu_en</code> is low, the module bypasses ReLU and passes <code>input_data</code> directly to the next step.</p> </li> <li> <p>Quantization via Right Shift: The processed data then undergoes an arithmetic right shift by the value specified in <code>shift_amount</code>. This step performs quantization, reducing the precision of the data to fit within <code>OUTPUT_WIDTH</code> bits.</p> </li> <li> <p>Truncation to Output Width: After shifting, the result is truncated to <code>OUTPUT_WIDTH</code> bits, producing the quantized output in <code>result</code>. The <code>valid_o</code> signal indicates that the result is ready.</p> </li> </ol>"},{"location":"block/microarchitecture/activation/#example-relu-and-shift-logic","title":"Example: ReLU and Shift Logic","text":"<p>If <code>valid_i</code> is asserted:</p> <ul> <li> <p>When <code>relu_en</code> is high:</p> <ul> <li><code>relu_result</code> = max(<code>input_data</code>, 0)</li> </ul> </li> <li> <p>If <code>relu_en</code> is low:</p> <ul> <li><code>relu_result</code> = <code>input_data</code></li> </ul> </li> <li> <p>Shift: The <code>relu_result</code> is then right-shifted by <code>shift_amount</code>.</p> </li> <li>Output: The shifted data is truncated to <code>OUTPUT_WIDTH</code> bits and assigned to <code>result</code>, with <code>valid_o</code> set high.</li> </ul>"},{"location":"block/microarchitecture/activation/#diagram","title":"Diagram","text":"<p>The diagram is trivial.</p>"},{"location":"block/microarchitecture/activation/#related-files","title":"Related Files","text":"File Name Type hs_npu_activation Top Module"},{"location":"block/microarchitecture/executive/","title":"Executive","text":""},{"location":"block/microarchitecture/executive/#description","title":"Description","text":"<p>The <code>hs_npu_executive</code> module serves as the interface between the PeakRDL (autogenerated) CSR module and the memory ordering unit, managing control signals and configurations for the ScaleNPU system. It processes CSR values to configure layer parameters, matrix dimensions, and memory addresses. Additionally, it manages control flags for reusing inputs, applying bias, and selecting activation functions, along with interrupt signaling. This submodule coordinates between the CSR interface and memory ordering.</p> <p>This module also handles error codes and performs basic checks on the parameters passed in the CSRs, currently validating that the input size does not exceed the maximum input and output buffer size.</p> <p>Note</p> <p>If more error/exit codes are to be added, this module and the CSR module are the appropriate places to do so. For example, the memory interface always assumes memory does not fail. This module could connect to the memory interface and link to AXI failure signals so that, in case of a memory error, it is reported to the CPU.</p>"},{"location":"block/microarchitecture/executive/#io-table","title":"I/O Table","text":""},{"location":"block/microarchitecture/executive/#input-table","title":"Input Table","text":"Input Name Direction Type Description <code>clk</code> Input <code>logic</code> Clock signal for synchronization. <code>rst_n</code> Input <code>logic</code> Active-low reset signal. <code>hwif_out</code> Input <code>hs_npu_ctrlstatus_regs_pkg::hs_npu_ctrlstatus_regs__out_t</code> CSR output values for configuration and control flags. <code>memory_ordering_ready_i</code> Input <code>logic</code> Indicates readiness from the memory ordering unit for new commands. <code>finished</code> Input <code>logic</code> Signal indicating completion of the current task."},{"location":"block/microarchitecture/executive/#output-table","title":"Output Table","text":"Output Name Direction Type Description <code>hwif_in</code> Output <code>hs_npu_ctrlstatus_regs_pkg::hs_npu_ctrlstatus_regs__in_t</code> CSR input signals to update internal states and trigger interrupts. <code>irq</code> Output <code>logic</code> Interrupt request signal for the CPU upon task completion. <code>memory_ordering_valid_o</code> Output <code>logic</code> Valid signal indicating new command for memory ordering unit. <code>num_input_rows_out</code> Output <code>uword</code> Number of rows in the input matrix from the CSR. <code>num_input_columns_out</code> Output <code>uword</code> Number of columns in the input matrix from the CSR. <code>num_weight_rows_out</code> Output <code>uword</code> Number of rows in the weight matrix from the CSR. <code>num_weight_columns_out</code> Output <code>uword</code> Number of columns in the weight matrix from the CSR. <code>reuse_inputs_out</code> Output <code>logic</code> Flag to reuse input data across computations. <code>reuse_weights_out</code> Output <code>logic</code> Flag to reuse weights across computations. <code>save_outputs_out</code> Output <code>logic</code> Flag to save computation outputs. <code>use_bias_out</code> Output <code>logic</code> Enables bias in the computation. <code>use_sum_out</code> Output <code>logic</code> Enables sum accumulation in the computation. <code>shift_amount_out</code> Output <code>uword</code> Shift amount for adjusting results post-computation. <code>activation_select_out</code> Output <code>logic</code> Activation function selection for computation. <code>base_address_out</code> Output <code>uword</code> Base memory address for data access. <code>result_address_out</code> Output <code>uword</code> Memory address for storing results."},{"location":"block/microarchitecture/executive/#submodule-diagram","title":"Submodule Diagram","text":"<p>The diagram is trivial.</p>"},{"location":"block/microarchitecture/executive/#related-files","title":"Related Files","text":"File Name Description hs_npu_executive Top module hs_npu_ctrlstatus_regs Defines CSR structure and types used by the module. <p>Note</p> <p>The actual .sv of the CSRs is autogenerated by PeakRDL. Look within the \\regblock directory inside \\build to find it.</p>"},{"location":"block/microarchitecture/fifo/","title":"FIFO Module","text":""},{"location":"block/microarchitecture/fifo/#description","title":"Description","text":"<p>The FIFO (First-In, First-Out) module in the ScaleNPU functions as a sequence of specialized buffers that temporarily store and manage data flow between different processing stages. Instead of a centralized buffer for the entire NPU, the ScaleNPU utilizes multiple FIFO instances, each serving a specific role, this enables parallel data storage and retrieval within the NPU.</p> <p>The FIFO sequentially stores incoming data (<code>in</code>) as long as the <code>valid_i</code> and <code>ready_o</code> signals are active. When data is requested (<code>ready_i</code> asserted), it outputs in the order stored, one value per cycle. The <code>ready_o</code> output indicates if more data can be written to the FIFO, while <code>valid_o</code> shows if valid data is available for reading. The <code>flush</code> signal resets the FIFO state.</p> <p>A unique feature of the ScaleNPU FIFO is its custom <code>reread</code> signal. the <code>reread</code> signal resets the read pointer, allowing data to be output again, which a normal FIFO is not able to do. </p> <p>In the <code>hs_npu_fifo</code> module, <code>WIDTH</code> defines the bit width of each entry, making the FIFO adaptable to handle data sizes ranging from small values (e.g., 8-bit) to larger ones (e.g., 32-bit), while <code>DEPTH</code> specifies the number of entries the FIFO can hold, setting its capacity before it is full. The data input (<code>in</code>) and output (<code>out</code>) signals are sized according to <code>WIDTH</code>, aligning with the bit size of data being processed, and the internal array is sized <code>[DEPTH][WIDTH]</code>.</p>"},{"location":"block/microarchitecture/fifo/#io-table","title":"I/O Table","text":""},{"location":"block/microarchitecture/fifo/#input-table","title":"Input Table","text":"Input Name Direction Type Description <code>clk_core</code> Input <code>logic</code> Clock signal for synchronization. <code>rst_core_n</code> Input <code>logic</code> Active-low reset signal for initializing the FIFO state. <code>flush</code> Input <code>logic</code> Resets the FIFO state and clears data. <code>reread</code> Input <code>logic</code> Resets the read pointer to reread all stored data. <code>valid_i</code> Input <code>logic</code> Indicates if the input data is valid for writing. <code>in</code> Input <code>logic [WIDTH-1:0]</code> Data input for values to be stored in the FIFO. <code>ready_i</code> Input <code>logic</code> Indicates if the output can be accepted by the consumer."},{"location":"block/microarchitecture/fifo/#output-table","title":"Output Table","text":"Output Name Direction Type Description <code>ready_o</code> Output <code>logic</code> Indicates if the FIFO can accept more data. <code>valid_o</code> Output <code>logic</code> Indicates if the FIFO has valid data available to read. <code>out</code> Output <code>logic [WIDTH-1:0]</code> Data output line for values retrieved from the FIFO."},{"location":"block/microarchitecture/fifo/#submodule-diagram","title":"Submodule Diagram","text":"<p>The following diagram illustrates the FIFO module, its inputs, outputs, and internal signal paths.</p> fifo"},{"location":"block/microarchitecture/fifo/#related-files","title":"Related Files","text":"File Name Type hs_npu_fifo Top"},{"location":"block/microarchitecture/gatekeeper/","title":"Gatekeeper Module","text":""},{"location":"block/microarchitecture/gatekeeper/#description","title":"Description","text":"<p>The Gatekeeper module (<code>hs_npu_gatekeeper</code>) in the ScaleNPU serves as a control sub-unit that regulates data flow to and from the NPU's computational units, ensuring synchronization based on specified enable cycles. It manages data forwarding based on a configurable number of cycles (<code>enable_cycles_in</code>) during which it remains active. The Gatekeeper operates by receiving input data (<code>input_data</code>) and either passes this data through to the next stage (<code>output_data</code>) or discards it (sets <code>output_data</code> to 0), depending on its active state.</p> <p>The <code>start_in</code> signal (which should only last one cycle) triggers the gatekeeper to initiate the enable cycle countdown. When active, the <code>output_data</code> mirrors the <code>input_data</code>. The <code>start_out</code> signal propagates the start signal to subsequent gatekeepers (with a one cycle delay), enabling a chain of controlled data handoffs across processing units.</p> <p>Key functionality includes the <code>active</code> signal, which behaves like a ready or valid flag and indicates when data can be processed by/from the module.</p> <p>The <code>DATA_WIDTH</code> parameter defines the bit width of both input and output data, making the Gatekeeper adaptable to a range of data sizes, from small (e.g., 8-bit) to larger values (e.g., 32-bit).</p> <p>The Gatekeeper module is implemented as an array to form the \"sequencer\" blocks shown in the ScaleNPU diagram. The Gatekeeper was specifically designed to achieve the \"diagonal delay\" in the inputs of the systolic array and to manage its corresponding \"diagonal\" output. This functionality will be discussed in more detail in later sections.</p>"},{"location":"block/microarchitecture/gatekeeper/#io-table","title":"I/O Table","text":""},{"location":"block/microarchitecture/gatekeeper/#input-table","title":"Input Table","text":"Input Name Direction Type Description <code>clk</code> Input <code>logic</code> Clock signal for synchronization. <code>rst_n</code> Input <code>logic</code> Active-low reset signal to initialize Gatekeeper state. <code>input_data</code> Input <code>logic [DATA_WIDTH-1:0]</code> Data input to be controlled by the Gatekeeper. <code>enable_cycles_in</code> Input <code>uword</code> Number of cycles for which the Gatekeeper remains active. <code>start_in</code> Input <code>logic</code> Start signal to initiate the Gatekeeper enable cycles."},{"location":"block/microarchitecture/gatekeeper/#output-table","title":"Output Table","text":"Output Name Direction Type Description <code>output_data</code> Output <code>logic [DATA_WIDTH-1:0]</code> Data output to be passed to the next module. <code>start_out</code> Output <code>logic</code> Propagates the start signal to subsequent Gatekeepers. <code>active</code> Output <code>logic</code> Indicates if the Gatekeeper is active and ready to output data."},{"location":"block/microarchitecture/gatekeeper/#submodule-diagram","title":"Submodule Diagram","text":"<p>The following diagram illustrates the Gatekeeper module, its inputs, outputs, and internal signal paths.</p> gatekeeper"},{"location":"block/microarchitecture/gatekeeper/#related-files","title":"Related Files","text":"File Name Type hs_npu_gatekeeper Top"},{"location":"block/microarchitecture/inference/","title":"Inference Module","text":""},{"location":"block/microarchitecture/inference/#description","title":"Description","text":"<p>The Inference Module (<code>hs_npu_inference</code>) is the computational core of the ScaleNPU, integrating all primary submodules (matrix multiplication, accumulation, activation, and output buffering) to perform matrix-based neural network inference. This module manages data flow between subunits to achieve matrix multiplication, bias addition, activation, quantization, and buffering of results. Only control and interface modules are external to this computation section.</p>"},{"location":"block/microarchitecture/inference/#features","title":"Features","text":"<ul> <li>Modular Subunits: Combines matrix multiplication, accumulation, activation (with quantization), and output FIFOs.</li> <li>Activation Flexibility: Support for multiple activation functions, with ReLU currently implemented.</li> <li>Configurable Data Precision: Supports distinct data widths and customizable quantization through a shift operation.</li> </ul>"},{"location":"block/microarchitecture/inference/#io-table","title":"I/O Table","text":""},{"location":"block/microarchitecture/inference/#input-table","title":"Input Table","text":"Input Name Direction Type Description <code>clk</code> Input <code>logic</code> Clock signal for synchronization. <code>rst_n</code> Input <code>logic</code> Active-low reset signal. <code>flush_input_fifos</code> Input <code>logic</code> Signal to flush the input FIFOs. <code>flush_weight_fifos</code> Input <code>logic</code> Signal to flush the weight FIFOs. <code>flush_output_fifos</code> Input <code>logic</code> Signal to flush the output FIFOs. <code>input_matrix_row</code> Input <code>logic[INPUT_DATA_WIDTH-1:0][SIZE]</code> Row of input data matrix for each row in the systolic array. <code>input_fifo_valid_i</code> Input <code>logic</code> Signal indicating valid data is present in <code>input_matrix_row</code>. <code>input_sums</code> Input <code>logic[OUTPUT_DATA_WIDTH-1:0][SIZE]</code> Initial sums for each row in the matrix multiplication unit. <code>weight_matrix_row</code> Input <code>logic[WEIGHT_DATA_WIDTH-1:0][SIZE]</code> Row of weight data matrix for each row in the systolic array. <code>weight_fifo_valid_i</code> Input <code>logic</code> Signal indicating valid data is present in <code>weight_matrix_row</code>. <code>enable_weights</code> Input <code>logic</code> Enable signal to load weights in the matrix multiplication unit. <code>start_input_gatekeeper</code> Input <code>logic</code> Start signal for the input gatekeeper. <code>start_output_gatekeeper</code> Input <code>logic</code> Start signal for the output gatekeeper. <code>enable_cycles_in</code> Input <code>uword</code> Cycles for enabling the matrix multiplication unit gatekeepers. <code>bias_values</code> Input <code>logic[OUTPUT_DATA_WIDTH-1:0][SIZE]</code> Bias values for each accumulator in the array. <code>bias_en</code> Input <code>logic</code> Enable signal for loading bias values in accumulators. <code>shift_amount</code> Input <code>uword</code> Shift amount for quantization in activation. <code>relu_enable</code> Input <code>logic</code> Enable signal for applying ReLU activation. <code>output_fifo_ready_i</code> Input <code>logic</code> Ready signal from the output FIFO gatekeeper. <code>output_fifo_reread</code> Input <code>logic</code> Signal to reread from output FIFOs."},{"location":"block/microarchitecture/inference/#output-table","title":"Output Table","text":"Output Name Direction Type Description <code>input_fifo_ready_o</code> Output <code>logic[SIZE]</code> Ready signal for each input FIFO row. <code>weight_fifo_ready_o</code> Output <code>logic[SIZE]</code> Ready signal for each weight FIFO row. <code>inference_result</code> Output <code>logic[ACTIVATION_OUTPUT_WIDTH-1:0][SIZE]</code> Final inference results after activation and quantization for each row. <code>output_fifo_valid_o</code> Output <code>logic[SIZE]</code> Valid signal for each output FIFO row."},{"location":"block/microarchitecture/inference/#module-behavior-and-data-flow","title":"Module Behavior and Data Flow","text":"<p>The inference module performs inference by coordinating data flow between its subunits, from input processing to final output generation:</p> <ol> <li> <p>Matrix Multiplication: Input and weight data are fed to the matrix multiplication unit (MMU), which computes the partial sums and forwards the results to each accumulator.</p> </li> <li> <p>Accumulation: Each accumulator adds a bias value to the output from the MMU, enabling fine-tuning of the final result.</p> </li> <li> <p>Activation &amp; Quantization: The activation unit applies the ReLU function and performs quantization by shifting the accumulated results. The final data is truncated to <code>ACTIVATION_OUTPUT_WIDTH</code> bits, yielding the processed inference results.</p> </li> <li> <p>Output Buffering: The processed data is stored in output FIFOs, which manage the data flow to external modules based on the <code>output_fifo_ready_i</code> signal.</p> </li> </ol>"},{"location":"block/microarchitecture/inference/#diagram","title":"Diagram","text":"<p>The following diagram illustrates the inference module, its inputs, outputs, and internal signal paths.</p> XPU"},{"location":"block/microarchitecture/inference/#related-files","title":"Related Files","text":"File Name Type hs_npu_inference Top Module hs_npu_mm_unit Submodule - Matrix Multiplication Unit hs_npu_accumulator Submodule - Accumulator hs_npu_activation Submodule - Activation and Quantization"},{"location":"block/microarchitecture/mac/","title":"MAC Module","text":""},{"location":"block/microarchitecture/mac/#description","title":"Description","text":"<p>The <code>hs_npu_mac</code> (Multiply-Accumulate) module in the ScaleNPU serves as the fundamental computational block for performing multiply-accumulate (MAC) operations, crucial for a wide variety of neural processing tasks. The module is designed to take in two values, perform element-wise multiplication, and accumulate the result into a running sum, providing the basis for complex computations, such as matrix multiplications. </p> <p>Each instance of <code>hs_npu_mac</code> operates independently, supporting parallel processing and enabling high-throughput computation across multiple elements. For applications like matrix multiplication, the inputs <code>a_in</code> and <code>b_in</code> can represent values from two matrices. The module multiplies these inputs, adds the result to an incoming <code>sum</code>, and outputs the result while forwarding the input values for further processing.</p>"},{"location":"block/microarchitecture/mac/#io-table","title":"I/O Table","text":""},{"location":"block/microarchitecture/mac/#input-table","title":"Input Table","text":"Input Name Direction Type Description <code>clk</code> Input <code>logic</code> Clock signal for synchronization. <code>enable_in</code> Input <code>logic</code> Enable signal that controls when <code>b_in</code> is registered. <code>a_in</code> Input <code>short</code> First input value for the MAC operation. <code>b_in</code> Input <code>short</code> Second input value for the MAC operation. <code>sum</code> Input <code>word</code> Running sum to which the product of <code>a_in</code> and <code>b_in</code> is added."},{"location":"block/microarchitecture/mac/#output-table","title":"Output Table","text":"Output Name Direction Type Description <code>a_out</code> Output <code>short</code> Forwarded output of <code>a_in</code> for use in subsequent operations. <code>b_out</code> Output <code>short</code> Forwarded output of <code>b_in</code> for use in subsequent operations. <code>result</code> Output <code>word</code> Output result of the multiply-accumulate operation \\( a \\times b + c \\)."},{"location":"block/microarchitecture/mac/#operation","title":"Operation","text":"<p>The <code>hs_npu_mac</code> module performs the multiply-accumulate operation as follows:</p> <ol> <li> <p>Receives <code>a_in</code> and <code>b_in</code> as inputs for multiplication. These inputs may represent values from two matrices in a matrix multiplication scenario.</p> </li> <li> <p>When <code>enable_in</code> is active, registers the <code>b_in</code> input value, allowing selective updates to the second operand in the multiplication. In our case this is for \"fixed weight\" inference.</p> </li> <li> <p>Performs the multiply-accumulate operation by calculating \\( (a\\_in \\times b\\_ff) + sum \\), where <code>b_ff</code> stores the last registered <code>b_in</code> value.</p> </li> <li> <p>Outputs the result of the operation in <code>result</code>.</p> </li> <li> <p>Forwards <code>a_ff</code> and <code>b_ff</code> as <code>a_out</code> and <code>b_out</code> to propagate values to the next MAC unit.</p> </li> </ol>"},{"location":"block/microarchitecture/mac/#internal-signals","title":"Internal Signals","text":"<ul> <li><code>a_ff</code>: Flip-flop register that stores the current value of <code>a_in</code>.</li> <li><code>b_ff</code>: Flip-flop register that stores the persistent value of <code>b_in</code> when <code>enable_in</code> is active.</li> </ul>"},{"location":"block/microarchitecture/mac/#submodule-diagram","title":"Submodule Diagram","text":"XPU-Page-5"},{"location":"block/microarchitecture/mac/#related-files","title":"Related Files","text":"File Name Type hs_npu_mac Top"},{"location":"block/microarchitecture/memory_interface/","title":"Memory Interface Unit","text":""},{"location":"block/microarchitecture/memory_interface/#description","title":"Description","text":"<p>The <code>hs_npu_memory_interface</code> module is designed to handle the AXI4 Burst transactions between the NPU's <code>hs_npu_memory_ordering</code> control module and the system memory. Acting as an intermediary, it translates read and write requests from the memory ordering module into AXI-compatible burst operations, enabling data transfers. This module is structured as a state machine, using the AXI protocol to facilitate reliable data flow in compliance with the timing and control requirements. Serving as a slave to the memory ordering module and as a master on the AXI interface, it manages data transfers to and from the NPU.</p>"},{"location":"block/microarchitecture/memory_interface/#overview-and-responsibilities","title":"Overview and Responsibilities","text":"<ol> <li> <p>AXI Protocol Compliance:</p> <ul> <li>The <code>hs_npu_memory_interface</code> observes the AXI protocol's handshaking and burst requirements, ensuring correct signal sequences during read and write operations. It aligns its burst sizes (<code>BURST_SIZE</code>) and lengths (<code>BURST_LEN</code>) with memory ordering specifications for each transfer.</li> </ul> </li> <li> <p>State Machine Operation:</p> <ul> <li>This module cycles through states\u2014<code>IDLE</code>, <code>READ</code>, <code>READ_WAIT</code>, and <code>WRITE</code>\u2014to control read and write processes. Each state is configured for a specific function, including waiting for AXI readiness signals, initiating data transfers, and managing burst counters.</li> </ul> </li> <li> <p>Data Tracking and Control:</p> <ul> <li>During write operations, the module tracks progress with internal signals (<code>clear_done</code>, <code>aw_done</code>, and <code>w_done</code>). For read operations, it maintains data availability and outputs <code>mem_valid_o</code> once data is ready, signaling to the memory ordering module that memory contents are valid.</li> </ul> </li> <li> <p>Internal Data Buffers and Tracking:</p> <ul> <li>The module uses internal buffers to hold burst data, including <code>memory_data_in_ff</code> for incoming memory data and <code>memory_data_out</code> for outgoing data. Burst counters track the current position within each transfer, while write control signals (<code>axi.awvalid</code>, <code>axi.wvalid</code>, <code>axi.wlast</code>) handle the finalization of AXI transactions.</li> </ul> </li> </ol>"},{"location":"block/microarchitecture/memory_interface/#state-descriptions","title":"State Descriptions","text":"<ul> <li> <p>IDLE: </p> <ul> <li>Awaits instructions from the memory ordering unit. If <code>mem_read_ready_i</code> is asserted, the state transitions to <code>READ</code>. For write operations (<code>mem_write_valid_i</code>), it moves to <code>WRITE</code>. If <code>mem_invalidate</code> is asserted, any ongoing read is canceled.</li> </ul> </li> <li> <p>READ:</p> <ul> <li>Initiates an AXI read burst from the address specified in <code>request_address</code>. If the request is invalidated, it returns to <code>IDLE</code>. Otherwise, once the AXI read address is accepted (<code>axi.arready</code>), it transitions to <code>READ_WAIT</code>.</li> </ul> </li> <li> <p>READ_WAIT:</p> <ul> <li>Manages data retrieval from the AXI bus. As each data beat is received, it updates <code>memory_data_out</code> for use by the memory ordering module. When the burst read completes (signaled by <code>axi.rlast</code>), it returns to <code>IDLE</code> with <code>mem_valid_o</code> asserted to indicate data validity.</li> </ul> </li> <li> <p>WRITE:</p> <ul> <li>Initiates an AXI write burst to the address in <code>request_address</code>, setting <code>axi.awaddr</code> and <code>axi.wdata</code> for each data word. The module continues writing until the final transfer (<code>axi.wlast</code>). After completion, it resets the state to <code>IDLE</code> for the next transfer.</li> </ul> </li> </ul>"},{"location":"block/microarchitecture/memory_interface/#control-signal-assignments","title":"Control Signal Assignments","text":"<ul> <li>mem_valid_o: Indicates when data is valid for the memory ordering module post-read.</li> <li>mem_ready_o: Signals readiness to accept new requests when in <code>IDLE</code>.</li> <li>axi.arvalid, axi.awvalid, axi.wvalid: Control signals for AXI read and write initiation.</li> <li>axi.wlast: Signals the last data transfer in a write burst.</li> <li>burst_counter and burst_counter_ff: Track the current position within each burst transfer.</li> </ul>"},{"location":"block/microarchitecture/memory_interface/#data-buffers-and-burst-handling","title":"Data Buffers and Burst Handling","text":"<ul> <li><code>memory_data_in</code> and <code>memory_data_out</code> are used to store data to/from memory. Burst counters manage the progression of data transfers within each burst, with <code>STRB</code> defining the byte lanes to be written during each AXI cycle.</li> </ul>"},{"location":"block/microarchitecture/memory_interface/#io-table","title":"I/O Table","text":""},{"location":"block/microarchitecture/memory_interface/#input-signals","title":"Input Signals","text":"Input Name Direction Type Description <code>clk</code> Input <code>logic</code> Clock signal for synchronous logic in the module. <code>rst_n</code> Input <code>logic</code> Active-low reset signal for initializing the module\u2019s internal state. <code>mem_read_ready_i</code> Input <code>logic</code> Indicates that the memory ordering module is ready to read data. <code>mem_write_valid_i</code> Input <code>logic</code> Indicates a write request from the memory ordering module. <code>mem_invalidate</code> Input <code>logic</code> Signal to cancel any ongoing read operation. <code>memory_data_in</code> Input <code>logic [BURST_SIZE-1:0]</code> Data from the memory ordering module for write operations. <code>request_address</code> Input <code>logic [ADDR_WIDTH-1:0]</code> Address from the memory ordering module to initiate a memory read or write."},{"location":"block/microarchitecture/memory_interface/#output-signals","title":"Output Signals","text":"Output Name Direction Type Description <code>mem_valid_o</code> Output <code>logic</code> Indicates that the data in <code>memory_data_out</code> is valid for reading. <code>mem_ready_o</code> Output <code>logic</code> Indicates that the memory interface is ready to accept a new read or write request. <code>memory_data_out</code> Output <code>logic [BURST_SIZE-1:0]</code> Data read from memory, sent to the memory ordering module."},{"location":"block/microarchitecture/memory_interface/#axi4-interface-signals","title":"AXI4 Interface Signals","text":"AXI Signal Direction Type Description <code>axi.arid</code> Output <code>logic [ID_WIDTH-1:0]</code> Read transaction ID. Set to 0. <code>axi.awid</code> Output <code>logic [ID_WIDTH-1:0]</code> Write transaction ID. Set to 0. <code>axi.araddr</code> Output <code>logic [ADDR_WIDTH-1:0]</code> Read address for the transaction. <code>axi.awaddr</code> Output <code>logic [ADDR_WIDTH-1:0]</code> Write address for the transaction. <code>axi.arburst</code> Output <code>logic [1:0]</code> Burst type for reads; set to <code>INCR</code> (incrementing burst). <code>axi.awburst</code> Output <code>logic [1:0]</code> Burst type for writes; set to <code>INCR</code> (incrementing burst). <code>axi.arsize</code> Output <code>logic [BURST_SIZE-1:0]</code> Data transfer size for reads. <code>axi.awsize</code> Output <code>logic [BURST_SIZE-1:0]</code> Data transfer size for writes. <code>axi.arlen</code> Output <code>logic [BURST_LEN-1:0]</code> Number of data transfers per burst for reads. <code>axi.awlen</code> Output <code>logic [BURST_LEN-1:0]</code> Number of data transfers per burst for writes. <code>axi.arvalid</code> Output <code>logic</code> Indicates that the read address and control signals are valid. <code>axi.awvalid</code> Output <code>logic</code> Indicates that the write address and control signals are valid. <code>axi.wdata</code> Output <code>logic [DATA_WIDTH-1:0]</code> Write data for the memory interface. <code>axi.wstrb</code> Output <code>logic [DATA_WIDTH/8-1:0]</code> Write strobe to indicate valid bytes in write data. <code>axi.wvalid</code> Output <code>logic</code> Indicates that write data is valid. <code>axi.bready</code> Output <code>logic</code> Signal to acknowledge completion of write transactions. <code>axi.rready</code> Output <code>logic</code> Signal to acknowledge receipt of read data from memory. <code>axi.rdata</code> Input <code>logic [DATA_WIDTH-1:0]</code> Read data returned from the memory interface. <code>axi.rid</code> Input <code>logic [ID_WIDTH-1:0]</code> ID tag for the read transaction. <code>axi.rresp</code> Input <code>logic [1:0]</code> Read response code indicating the result of the transaction. <code>axi.rvalid</code> Input <code>logic</code> Indicates that the read data and response are valid. <code>axi.bresp</code> Input <code>logic [1:0]</code> Write response code indicating the result of the transaction <code>axi.bid</code> Input <code>logic [ID_WIDTH-1:0]</code> ID tag for the write transaction response. <code>axi.bvalid</code> Input <code>logic</code> Indicates that the write response is valid."},{"location":"block/microarchitecture/memory_interface/#state-machine-diagram","title":"State machine diagram","text":"memory_interface_sm"},{"location":"block/microarchitecture/memory_interface/#related-files","title":"Related Files","text":"File Name Type hs_npu_memory_interface Top module"},{"location":"block/microarchitecture/memory_interface/#additional-comments","title":"Additional Comments","text":"<p>This module's biggest complication is the correct usage of the AXI4 protocol, specially when taking into account that simulation and on-device behaviours can differ. If this module is edited make sure to maintain compliance with said protocol. </p>"},{"location":"block/microarchitecture/memory_ordering/","title":"Memory Ordering Unit","text":""},{"location":"block/microarchitecture/memory_ordering/#description","title":"Description","text":"<p>The <code>hs_npu_memory_ordering</code> module is a control unit responsible for orchestrating data flow between memory and the inference unit in the NPU. It uses a state machine to manage loading of input matrices, weights, biases, and sums, as well as saving output data back to memory. Key functionalities include handling memory requests, controlling data read and write operations, and setting up FIFOs for input, weight, and output buffers. This module also supports reusing weights and inputs, applying biases, and shifting values for activation functions. Its execution can be configured through control signals, with outputs aligned for the systolic array dimensions, ensuring data preparation for matrix multiplication and inference tasks.</p>"},{"location":"block/microarchitecture/memory_ordering/#overview-and-responsibilities","title":"Overview and Responsibilities","text":"<ol> <li> <p>State Machine: </p> <ul> <li>The module transitions between states like <code>IDLE</code>, <code>LOADING_WEIGHTS</code>, <code>LOADING_INPUTS</code>, <code>LOADING_BIAS</code>, <code>LOADING_SUMS</code>, <code>READY_TO_COMPUTE</code>, and <code>SAVING</code>. Each state has specific responsibilities, and transitions occur based on conditions such as memory validity signals and reuse flags.</li> </ul> </li> <li> <p>Data Loading and Memory Requests: </p> <ul> <li>During the loading phases, this module issues memory requests and loads data (weights, inputs, bias, sums) from memory or previous inference results based on the configuration. It uses <code>BURST_SIZE</code> to control the amount of data per transfer.</li> </ul> <p>Danger</p> <p>As discussed earlier, changing the default value of <code>BURST_SIZE</code> might cause errors.</p> </li> <li> <p>Computation Control: </p> <ul> <li>In the <code>READY_TO_COMPUTE</code> state, the module controls gates (<code>start_input_gatekeeper</code> and <code>start_output_gatekeeper</code>) and enables the computation within the inference unit, coordinating the input and output flow through the gatekeepers.</li> </ul> <p>Info</p> <p>This is absolutely central to the NPU, as this timing is very sentitive, one cycle too early or too late will produce incomplete or incorrect results. </p> </li> <li> <p>Saving Results: </p> <ul> <li>After computation, in the <code>SAVING</code> state, it can write results back to memory if <code>save_outputs_in</code> is asserted. It uses memory write signals (<code>mem_write_valid_o</code> and <code>memory_data_out</code>) to save computed outputs sequentially.</li> </ul> </li> <li> <p>FIFO Control:</p> <ul> <li>The module manages FIFO flushing and readiness signals to synchronize data flow within the NPU, particularly for input, weight, and output FIFOs.</li> </ul> </li> </ol>"},{"location":"block/microarchitecture/memory_ordering/#state-descriptions","title":"State Descriptions","text":"<ul> <li> <p>IDLE: Initializes parameters and waits for a valid execution signal (<code>exec_valid_i</code>). When received, captures layer parameters, resets relevant counters, and transitions to <code>LOADING_WEIGHTS</code>.</p> </li> <li> <p>LOADING_WEIGHTS: Loads weights from memory into <code>output_weights</code> until the required rows are loaded or <code>reuse_weights</code> is set. When done, it transitions to <code>LOADING_INPUTS</code>.</p> </li> <li> <p>LOADING_INPUTS: Loads input data from memory (or reuses prior inputs if <code>reuse_inputs</code> is set). After loading, it transitions to <code>LOADING_BIAS</code>.</p> </li> <li> <p>LOADING_BIAS: If <code>use_bias</code> is asserted, loads bias values into <code>bias</code>. When completed, moves to <code>LOADING_SUMS</code>.</p> </li> <li> <p>LOADING_SUMS: Similar to the bias load, but for sums if <code>use_sum</code> is asserted. After loading, transitions to <code>READY_TO_COMPUTE</code>.</p> </li> <li> <p>READY_TO_COMPUTE: Activates input and output gatekeepers for controlled data flow into the inference unit. Sets up the module for computation based on <code>computation_cycles</code> and then transitions to <code>SAVING</code> to store results.</p> </li> <li> <p>SAVING: Saves the output data to memory if <code>save_outputs_in</code> is asserted. Once all data is saved, resets for the next cycle and goes back to <code>IDLE</code>.</p> <p>Info</p> <p>Note that the unit assumes that all the data is concurrently stored in memory, in a specific order!</p> </li> </ul>"},{"location":"block/microarchitecture/memory_ordering/#control-signal-assignments","title":"Control Signal Assignments","text":"<ul> <li>exec_ready_o: Indicates readiness for a new operation when in <code>IDLE</code>.</li> <li>mem_read_ready_o and mem_write_valid_o: Control memory read/write based on the state and internal flags.</li> <li>flush_input_fifos, flush_weight_fifos, and flush_output_fifos: Manage FIFO flushing in relevant states.</li> </ul>"},{"location":"block/microarchitecture/memory_ordering/#output-data-and-gatekeeper-configuration","title":"Output Data and Gatekeeper Configuration","text":"<ul> <li><code>output_weights</code>, <code>output_inputs</code>, <code>output_bias</code>, and <code>output_sums</code> hold data that will be transferred to inference and accumulation units.</li> <li><code>start_input_gatekeeper</code>, <code>start_output_gatekeeper</code>, and <code>enable_cycles_gatekeeper</code> configure gatekeepers, allowing smooth data flow within the processing unit.</li> </ul>"},{"location":"block/microarchitecture/memory_ordering/#io-table","title":"I/O Table","text":""},{"location":"block/microarchitecture/memory_ordering/#input-signals","title":"Input Signals","text":"Input Name Direction Type Description <code>clk</code> Input <code>logic</code> Clock signal for synchronization. <code>rst_n</code> Input <code>logic</code> Active-low reset signal. <code>exec_valid_i</code> Input <code>logic</code> Indicates that an execution request is valid. <code>mem_valid_i</code> Input <code>logic</code> Indicates that a memory read or write request is valid. <code>mem_ready_i</code> Input <code>logic</code> Memory interface ready signal for data transfers. <code>memory_data_in</code> Input <code>uword [BURST_SIZE]</code> Data matrix values read from memory. <code>num_input_rows_in</code> Input <code>uword</code> Number of rows in the input matrix. <code>num_input_columns_in</code> Input <code>uword</code> Number of columns in the input matrix. <code>num_weight_rows_in</code> Input <code>uword</code> Number of rows in the weight matrix. <code>num_weight_columns_in</code> Input <code>uword</code> Number of columns in the weight matrix. <code>reuse_inputs_in</code> Input <code>logic</code> Control signal to reuse inputs across computations. <code>reuse_weights_in</code> Input <code>logic</code> Control signal to reuse weights across computations. <code>save_outputs_in</code> Input <code>logic</code> Control signal to save outputs after computation. <code>use_bias_in</code> Input <code>logic</code> Enables bias addition in the computation. <code>use_sum_in</code> Input <code>logic</code> Enables sum accumulation in the computation. <code>shift_amount_in</code> Input <code>uword</code> Specifies the amount to shift results after computation. <code>activation_select_in</code> Input <code>logic</code> Selects the activation function to apply to results. <code>base_address_in</code> Input <code>uword</code> Base address for memory accesses. <code>result_address_in</code> Input <code>uword</code> Address to store the computation results. <code>inference_result</code> Input <code>logic [INPUT_DATA_WIDTH-1:0] [SIZE]</code> Final output from inference."},{"location":"block/microarchitecture/memory_ordering/#output-signals","title":"Output Signals","text":"Output Name Direction Type Description <code>exec_ready_o</code> Output <code>logic</code> Indicates readiness to accept a new execution command. <code>finished</code> Output <code>logic</code> Indicates that the current operation has completed. <code>mem_read_ready_o</code> Output <code>logic</code> Indicates readiness for memory read operations. <code>mem_write_valid_o</code> Output <code>logic</code> Indicates that a memory write operation is valid. <code>mem_invalidate</code> Output <code>logic</code> Signals to invalidate read data. <code>memory_data_out</code> Output <code>uword [BURST_SIZE]</code> Data matrix values written to memory. <code>request_address</code> Output <code>uword</code> Address for requesting data from memory. <code>flush_input_fifos</code> Output <code>logic</code> Signal to flush the input FIFOs. <code>input_fifo_valid_o</code> Output <code>logic</code> Indicates that data in input FIFO is valid. <code>flush_weight_fifos</code> Output <code>logic</code> Signal to flush the weight FIFOs. <code>weight_fifo_valid_o</code> Output <code>logic</code> Indicates that data in weight FIFO is valid. <code>flush_output_fifos</code> Output <code>logic</code> Signal to flush the output FIFOs. <code>output_fifo_ready_o</code> Output <code>logic</code> Indicates that the output FIFO is ready. <code>output_fifo_reread</code> Output <code>logic</code> Signal to reread data from the output FIFO. <code>bias_enable</code> Output <code>logic</code> Enable signal for bias in computation. <code>weight_enable</code> Output <code>logic</code> Enable signal for weight data in computation. <code>start_input_gatekeeper</code> Output <code>logic</code> Signal to start the input gatekeeper. <code>start_output_gatekeeper</code> Output <code>logic</code> Signal to start the output gatekeeper. <code>enable_cycles_gatekeeper</code> Output <code>uword</code> Number of cycles for enabling the gatekeeper. <code>activation_select_out</code> Output <code>logic</code> Output activation function selection. <code>shift_amount_out</code> Output <code>uword</code> Output shift amount for the computation result. <code>output_weights</code> Output <code>logic [INPUT_DATA_WIDTH-1:0] [SIZE]</code> Output weight matrix values. <code>output_inputs</code> Output <code>logic [INPUT_DATA_WIDTH-1:0] [SIZE]</code> Output input matrix values. <code>output_bias</code> Output <code>logic [OUTPUT_DATA_WIDTH-1:0] [SIZE]</code> Output bias values. <code>output_sums</code> Output <code>logic [OUTPUT_DATA_WIDTH-1:0] [SIZE]</code> Output sums balues."},{"location":"block/microarchitecture/memory_ordering/#state-machine-diagram","title":"State Machine Diagram","text":"<p>This diagram presents a basic overview of the state machine and its transitions.</p> memory_ordering_sm"},{"location":"block/microarchitecture/memory_ordering/#related-files","title":"Related Files","text":"File Name Type hs_npu_memory_ordering Top"},{"location":"block/microarchitecture/memory_ordering/#additional-comments","title":"Additional Comments","text":"<p>As discussed earlier, refactoring this module would resolve most of the current inflexibilities of the ScaleNPU in terms of sizes and parameters. Up until now, following the uarch section order, this is the only module that hardcodes specific sizes and parameters into the logic.</p> <p>It should also be noted that this module is quite complex, having to manage both the AXI sizes, bursts, and synchronization, along with the MM unit requirements and special timing. While this flexibility would provide a nice boost in performance, using the default values (whose correct functionality has been validated) is still significantly faster than using the ScaleCore-V for inference. The current pain point is the software interface, as the programmer must directly interact with the CSRs. A software driver would be the most beneficial addition to the ScaleNPU at this time.</p>"},{"location":"block/microarchitecture/mm_unit/","title":"Matrix Multiply Unit (MM Unit) Module","text":""},{"location":"block/microarchitecture/mm_unit/#description","title":"Description","text":"<p>The Matrix Multiply Unit (<code>hs_npu_mm_unit</code>) is designed to execute matrix multiplication operations efficiently as part of the ScaleNPU, leveraging a scalable systolic array structure. This module orchestrates data flow from input FIFOs to a systolic array, managing matrix inputs and controlling data propagation with gatekeepers to achieve a \"diagonal delay,\" which enables proper timing and alignment of data across matrix rows and columns during computation.</p> <p>The systolic array structure allows Matrix A (input data) to flow horizontally and Matrix B (weight data) to flow vertically through the array, with each multiplication and accumulation taking place synchronously at each node. The data comes from internal memory units implemented as a array of FIFOs and the results are re-organized by gatekeeper modules at the end of the systolic array.</p> <p>Note</p> <p>For a deeper understanding of systolic architectures and how matrix multiplication is implemented in this design, see this reference article. This is one of the most important and uselful sources the designers used to create the whole NPU!!</p>"},{"location":"block/microarchitecture/mm_unit/#parameters","title":"Parameters","text":"Parameter Name Type Default Description <code>SIZE</code> int 8 Size of the systolic array (dimensions <code>SIZE x SIZE</code>). <code>INPUT_DATA_WIDTH</code> int 16 Width of input data for Matrix A (int8). <code>OUTPUT_DATA_WIDTH</code> int 32 Width of output data (int32). <code>WEIGHT_DATA_WIDTH</code> int 16 Width of weight data for Matrix B (int8). <code>INPUT_FIFO_DEPTH</code> int 10 Depth of input FIFOs. <code>WEIGHT_FIFO_DEPTH</code> int 8 Depth of weight FIFOs (generally set equal to or greater than the systolic array size). <p>By default 16 bit are is used to prevent overflow, yet all the weight and input data should be 8 bit.</p>"},{"location":"block/microarchitecture/mm_unit/#io-table","title":"I/O Table","text":""},{"location":"block/microarchitecture/mm_unit/#input-table","title":"Input Table","text":"Input Name Direction Type Description <code>clk</code> Input <code>logic</code> Clock signal for synchronization. <code>rst_n</code> Input <code>logic</code> Reset signal, active-low. <code>flush_input_fifos</code> Input <code>logic</code> Flush signal for input FIFOs. <code>flush_weight_fifos</code> Input <code>logic</code> Flush signal for weight FIFOs. <code>input_matrix_row</code> Input <code>logic[INPUT_DATA_WIDTH-1:0][SIZE]</code> Row of the input matrix (Matrix A) for FIFO input. <code>input_fifo_valid_i</code> Input <code>logic</code> Valid signal for input FIFOs. <code>weight_matrix_row</code> Input <code>logic[WEIGHT_DATA_WIDTH-1:0][SIZE]</code> Row of the weight matrix (Matrix B) for FIFO input. <code>weight_fifo_valid_i</code> Input <code>logic</code> Valid signal for weight FIFOs. <code>input_sums</code> Input <code>logic[OUTPUT_DATA_WIDTH-1:0][SIZE]</code> Initial sum values for systolic array computation. <code>enable_weights</code> Input <code>logic</code> Enable signal for weights input to the systolic array. <code>start_input_gatekeeper</code> Input <code>logic</code> Start signal for the first input gatekeeper, cascading the start for others. <code>start_output_gatekeeper</code> Input <code>logic</code> Start signal for the first output gatekeeper, cascading the start for others. <code>enable_cycles_in</code> Input <code>uword</code> Number of cycles to enable gatekeepers for synchronized data flow."},{"location":"block/microarchitecture/mm_unit/#output-table","title":"Output Table","text":"Output Name Direction Type Description <code>input_fifo_ready_o</code> Output <code>logic[SIZE]</code> Ready signal array for input FIFOs. <code>weight_fifo_ready_o</code> Output <code>logic[SIZE]</code> Ready signal array for weight FIFOs. <code>output_data</code> Output <code>logic[OUTPUT_DATA_WIDTH-1:0][SIZE]</code> Computed output data from the systolic array. <code>valid_o</code> Output <code>logic[SIZE]</code> Valid signal array for output data availability."},{"location":"block/microarchitecture/mm_unit/#module-behavior-and-data-flow","title":"Module Behavior and Data Flow","text":"<ul> <li> <p>Input FIFOs and Gatekeepers: Each element of Matrix A (input data) flows through an input FIFO and gatekeeper before reaching the systolic array. Gatekeepers create a \"diagonal delay\" effect, allowing data to arrive in staggered cycles, so that the systolic array aligns row and column inputs correctly for matrix multiplication.</p> </li> <li> <p>Weight FIFOs: Each element of Matrix B (weight data) flows directly from a FIFO into the systolic array. The weights propagate vertically through columns without delay.</p> </li> <li> <p>Systolic Array Operation: The systolic array performs multiply-accumulate operations on data as it propagates across rows (Matrix A) and down columns (Matrix B), computing partial sums at each node. The computed results are passed downwards and accumulated row by row until reaching the final row, where they are collected as the final output.</p> </li> <li> <p>Output Gatekeepers: Output data from the systolic array is passed through a series of gatekeepers, synchronizing results and controlling output timing. The first output gatekeeper initiates externally, while subsequent ones cascade signals.</p> </li> </ul>"},{"location":"block/microarchitecture/mm_unit/#submodule-diagram","title":"Submodule Diagram","text":"<p>The following diagram illustrates the MM Unit\u2019s components and data flow paths, including input FIFOs, gatekeepers, and the systolic array\u2019s integration.</p> XPU"},{"location":"block/microarchitecture/mm_unit/#related-files","title":"Related Files","text":"File Name Type hs_npu_mm_unit Top Module hs_npu_fifo Submodule - FIFO hs_npu_gatekeeper Submodule - Gatekeeper hs_npu_systolic Submodule - Systolic Array Emulation C++ model emulating this block"},{"location":"block/microarchitecture/preamble/","title":"Preamble","text":""},{"location":"block/microarchitecture/preamble/#microarchitecture-overview","title":"Microarchitecture Overview","text":"<p>The following sections detail each of the NPU modules, explaining their functionality and the flow of data through the architecture. If this is your first time reading the document, we recommend following the sections in order, as they build upon each other in terms of concepts and implementation, making it easier to grasp the next module after understanding the previous one.</p>"},{"location":"block/microarchitecture/preamble/#basics-and-core-concepts","title":"Basics and Core Concepts","text":"<p>This section provides foundational knowledge for understanding the NPU design. If you are already familiar with NPUs, feel free to skip ahead.</p> <p>The NPU\u2019s primary goal is to accelerate inference for pretrained neural networks, focusing on fast and efficient matrix multiplication. Matrix multiplication, as you might know, involves multiplying and summing the elements of two matrices. In hardware, this is achieved through a systolic array of interconnected Multiply-Accumulate units (MACs). In machine learning, the result is then combined with a bias value and passed through an activation function, which forms the core of the NPU's computation. To manage memory limitations and ensure efficient computation, we also use symmetric power-of-2 quantization, which discards bits by shifting them left.</p> <p>Beyond computation, the NPU manages storage and control:</p> <ul> <li>Storage handles the retrieval and internal storage of inputs, weights, and biases, as well as how results are sent back to memory.</li> <li>Control coordinates data movement within the NPU and manages communication and instructions from the CPU.</li> </ul>"},{"location":"block/microarchitecture/preamble/#npu-operation-flow","title":"NPU Operation Flow","text":"<p>The NPU generally follows these steps:</p> <ol> <li> <p>Configuration: The CPU fills Control Status Registers with configuration data, including an \"init\" register that starts the process. Before this the CPU must have loaded inputs, weights, biases, and sums into memory.</p> </li> <li> <p>Verification: The NPU checks the provided data. If everything is valid, it proceeds to the next stage.</p> </li> <li> <p>Loading Data:</p> </li> <li> <p>Weights, Inputs, Biases, and Sums: First, weights are loaded into the NPU\u2019s internal storage. Then process repeats for inputs, biases, and sums. Control Status Registers can be configured to skip one or more of these steps. Inputs are often not loaded from memory but instead come from the results of previous run, allowing internal transfer between memory modules.</p> </li> <li> <p>Computation:</p> </li> <li>Weight Loading: Weights are loaded into the systolic array.</li> <li> <p>Input Flow: Once the systolic array is full, weights are locked, and inputs flow through the array in a specific order, which matches the order in which results are produced.</p> </li> <li> <p>Result Generation: After a certain number of cycles, the NPU begins producing results while still processing some inputs, as detailed in the systolic array section. Results are stored and ordered as they are generated.</p> </li> <li> <p>Result Storage: Depending on the CSR configuration, results may be stored back into memory. If storing is disabled, the process simply concludes. Intermediate results may be skipped to avoid the slow access to memory, which is typically useful only for debugging.</p> </li> <li> <p>Completion: When the process is completed the NPU sends a IRQ signal to the CPU. This includes the singal itself and a exit code value is set to a specific CSR, so that the CPU knows if the execution concluded successfully.</p> </li> </ol> <p>It\u2019s important to note that the NPU itself is agnostic to the larger inference process\u2014it simply performs matrix multiplication and applies functions. Software manages the higher-level logic. A single NPU operation represents just one layer of the neural network, so for a multilayer perceptron, the process must be repeated for each layer. CSRs can also disable activation functions, quantization, and biases, effectively turning the NPU into a standard matrix multiplier.</p> <p>Note</p> <p>You might wonder how the NPU handles matrix multiplications that exceed the size of the systolic array. The short answer is, it doesn\u2019t; software needs to divide large matrices into smaller chunks. Fortunately, matrix multiplication can be split into multiple smaller multiplications. The NPU includes \"sum\" values specifically for this purpose. While technically these sums could be managed by adjusting the bias values, they are provided separately for simplicity.</p>"},{"location":"block/microarchitecture/systolic/","title":"Systolic Array Module","text":""},{"location":"block/microarchitecture/systolic/#description","title":"Description","text":"<p>The Systolic Array module (<code>hs_npu_systolic</code>) is the central computational component of the ScaleNPU, designed to perform efficient matrix multiplication using a systolic array structure. This module orchestrates the flow of data through an <code>SIZE x SIZE</code> grid of MAC units. The array processes elements from two input matrices (matrix A and matrix B). Elements of Matrix B propagate vertically through columns, while elements of Matrix A flow horizontally across rows. The systolic array enables synchronized multiplication and accumulation at each node, with the results passing to the next row.</p> <p>The <code>SIZE</code> parameter defines the dimensions of the systolic array, making it scalable for various matrix sizes.</p> <p>Note</p> <p>For the NPU, matrix A is the input matrix and matrix B is the weight matrix.</p>"},{"location":"block/microarchitecture/systolic/#io-table","title":"I/O Table","text":""},{"location":"block/microarchitecture/systolic/#input-table","title":"Input Table","text":"Input Name Direction Type Description <code>clk</code> Input <code>logic</code> Clock signal for synchronization across MAC units. <code>enable_in</code> Input <code>logic</code> Enable signal to activate the flow of Matrix B values. <code>matrixA</code> Input <code>short[SIZE]</code> Input values for Matrix A, with each element feeding one row. <code>matrixB</code> Input <code>short[SIZE]</code> Input values for Matrix B, with each element feeding one column. <code>sum_in</code> Input <code>word[SIZE]</code> Initial sums for the first row of MAC units."},{"location":"block/microarchitecture/systolic/#output-table","title":"Output Table","text":"Output Name Direction Type Description <code>result</code> Output <code>word[SIZE]</code> Final computed values from the last row of MAC units."},{"location":"block/microarchitecture/systolic/#module-behavior-and-data-flow","title":"Module Behavior and Data Flow","text":"<p>This subsection does not prescribe a \"correct\" usage, as the systolic array can be used in several ways; nevertheless, this explains the specific way it is used in the NPU:</p> <ul> <li> <p>Matrix B values are injected into the first row of the array. These values propagate downward (one row per cycle) if <code>enable_in</code> is set. If <code>enable_in</code> is not set, the last value is stored and used by each MAC unit as the B operand.</p> </li> <li> <p>Matrix A values enter the first row and always propagate from right to left. The immediate value at the input is used as operand A by the MAC unit.</p> </li> <li> <p>Each MAC unit performs a multiply-accumulate operation using the inputs from its left (A values) and top (B values). Results are propagated downward and used as the SUM operand by the below MAC unit.</p> </li> </ul>"},{"location":"block/microarchitecture/systolic/#submodule-diagram","title":"Submodule Diagram","text":"<p>The following diagram illustrates the Systolic Array module, showing the flow of inputs, outputs, and internal signal paths.</p> XPU"},{"location":"block/microarchitecture/systolic/#related-files","title":"Related Files","text":"File Name Type hs_npu_systolic Top hs_npu_mac Submodule - MAC"}]}